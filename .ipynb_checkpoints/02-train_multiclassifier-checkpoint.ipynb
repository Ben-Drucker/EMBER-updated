{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata_utils\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmulticlassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m     16\u001b[0m seedy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m666\u001b[39m\n\u001b[1;32m     17\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seedy)\n",
      "File \u001b[0;32m/qfs/people/druc594/ML/EMBER-updated/multiclassifier.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fams \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/fam_distances_blos62/fams.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,conv_drpt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,mlp_drpt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import Audio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from multiclassifier import Model\n",
    "\n",
    "seedy = 666\n",
    "random.seed(seedy)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meow function to run after model is finished training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    return \"All Done!\" # Audio('meow.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load motif data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_motifs = np.genfromtxt('data/7472_motifs.csv',dtype='U')\n",
    "train_motifxFamMatrix = np.genfromtxt('data/7472_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "test_motifs = np.genfromtxt('data/1643_motifs.csv',dtype='U')\n",
    "test_motifxFamMatrix = np.genfromtxt('data/1643_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "fams = np.genfromtxt('data/large_fams.csv',dtype='U')\n",
    "\n",
    "## Split data into folds in a stratified k-fold manner.\n",
    "\n",
    "def proba_mass_split(y, folds=5):\n",
    "    obs, classes = y.shape\n",
    "    dist = y.sum(axis=0).astype('float')\n",
    "    dist /= dist.sum()\n",
    "    index_list = []\n",
    "    fold_dist = np.zeros((folds, classes), dtype='float')\n",
    "    for _ in range(folds):\n",
    "        index_list.append([])\n",
    "    for i in range(obs):\n",
    "        if i < folds:\n",
    "            target_fold = i\n",
    "        else:\n",
    "            normed_folds = fold_dist.T / fold_dist.sum(axis=1)\n",
    "            how_off = normed_folds.T - dist\n",
    "            target_fold = np.argmin(np.dot((y[i] - .5).reshape(1, -1), how_off.T))\n",
    "        fold_dist[target_fold] += y[i]\n",
    "        index_list[target_fold].append(i)\n",
    "    return index_list\n",
    "\n",
    "np.random.seed(seedy)\n",
    "folds = proba_mass_split(train_motifxFamMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embedding coordinates and kinase family distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Get Siamese embedding coords.\n",
    "#############################################\n",
    "\n",
    "embedding = np.genfromtxt('MODELS_siam/emb_??_embedding.csv',delimiter=',',dtype=float)\n",
    "train_embedding = embedding[ :len(train_motifs) ]\n",
    "test_embedding = embedding[ len(train_motifs): ]\n",
    "print(embedding.shape)\n",
    "\n",
    "#############################################\n",
    "# Get fam distance matrix for Phylo MSE loss.\n",
    "#############################################\n",
    "\n",
    "all_fams = (np.genfromtxt('data/fam_distances_blos62/fams.csv',dtype='U'))\n",
    "dist_matrix = (np.genfromtxt('data/fam_distances_blos62/dist_matr_new.csv',delimiter=',',dtype=float))\n",
    "\n",
    "fam_idc = [np.where(all_fams==fam)[0][0] for fam in fams]\n",
    "fam_dist_matrix = dist_matrix[fam_idc][:,fam_idc]\n",
    "        \n",
    "# normalize fam distances\n",
    "fMax = np.max(fam_dist_matrix)\n",
    "fMin = np.min(fam_dist_matrix)\n",
    "\n",
    "fam_dist_matrix_scaled = np.array((fam_dist_matrix))\n",
    "for i in range(len(fams)):\n",
    "    for j in range(len(fams)):\n",
    "        fam_dist_matrix_scaled[i][j] = 1 - float(fam_dist_matrix[i][j]-fMin)/(fMax-fMin) \n",
    "fam_dist_matrix = fam_dist_matrix_scaled\n",
    "\n",
    "famDistMatrix = fam_dist_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc functions for data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINOS = 'XWGSAELQDMPFTRIHVNCY_K'\n",
    "\n",
    "def get_oneHot_motifs(motifs, AMINOS=AMINOS):\n",
    "    oneHot_motifs = []\n",
    "    for motif in motifs:\n",
    "        one_hotted = np.zeros((len(motif), len(AMINOS)),dtype=float)\n",
    "        for i,aa in enumerate(motif):\n",
    "            hot = AMINOS.find(aa)\n",
    "            one_hotted[i][hot] = 1\n",
    "        oneHot_motifs.append(one_hotted)\n",
    "    oneHot_motifs = np.asarray(oneHot_motifs)\n",
    "    oneHot_motifs = np.swapaxes(oneHot_motifs,1,2)\n",
    "    return oneHot_motifs\n",
    "\n",
    "def get_stacked_features(motifs, embeddings):\n",
    "    oneHot_motifs = get_oneHot_motifs(motifs)\n",
    "    squished_oneHots = oneHot_motifs.reshape(oneHot_motifs.shape[0],oneHot_motifs.shape[1]*\n",
    "                                         oneHot_motifs.shape[2])\n",
    "    stacked_features = np.hstack((squished_oneHots,embeddings))\n",
    "    stacked_features = torch.tensor(stacked_features)\n",
    "    return stacked_features        \n",
    "\n",
    "\n",
    "def get_loader(motifs,embedding,motifxFamMatrix,idc,my_batch):\n",
    "    these_motifs = motifs[idc]\n",
    "    this_embedding = embedding[idc]\n",
    "    X = get_stacked_features(these_motifs,this_embedding)\n",
    "    Y = torch.tensor(motifxFamMatrix[idc])\n",
    "    dataset = data_utils.TensorDataset(X, Y)\n",
    "    loader = data_utils.DataLoader(dataset, batch_size=my_batch, shuffle=True, drop_last=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_microROC(y_test, y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(len(fams)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    return auc(fpr_micro, tpr_micro)\n",
    "\n",
    "def train_model(train_loader, val_loader, model, optimizer, batch_size, num_epochs, stopper='loss', \n",
    "                version='seq-coord', this_loss='phylo'):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    running = - math.inf\n",
    "    current = running\n",
    "    best_run = 0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(\"Epoch\",epoch+1)\n",
    "        for phase in ['train','validate']:\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            if phase=='train':\n",
    "                loader = train_loader\n",
    "                model.train()\n",
    "            else:\n",
    "                loader = val_loader\n",
    "                model.eval()\n",
    "                \n",
    "            for inputs,labels in loader:\n",
    "                inputs = inputs.float().to(device)\n",
    "                labels = labels.float().to(device)\n",
    "                motif = inputs[:,:-embedding.shape[1]].reshape( batch_size, len(AMINOS), len(train_motifs[0]) )\n",
    "                coords = inputs[:,-embedding.shape[1]:]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model.forward(motif, coords, version)\n",
    "                    if this_loss=='phylo' and version=='seq-coord':\n",
    "                        loss = phylo_error(outputs,labels)\n",
    "                    elif this_loss!='phylo':\n",
    "                        criterion = nn.BCELoss() # BCE loss is the usual loss to use.\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                y_test = np.asarray(labels.cpu())\n",
    "                y_score = outputs.cpu().detach().numpy()\n",
    "                acc = get_microROC(y_test, y_score)\n",
    "                running_acc += acc\n",
    "            \n",
    "            loss = running_loss / len(loader) \n",
    "            acc =  running_acc / len(loader) \n",
    "            \n",
    "            if phase=='train':\n",
    "                train_losses.append(loss)\n",
    "                train_accs.append(acc)\n",
    "                \n",
    "            elif phase=='validate':\n",
    "                val_losses.append(loss)\n",
    "                val_accs.append(acc)\n",
    "                \n",
    "                if stopper=='loss':\n",
    "                    current = -loss\n",
    "                elif stopper=='acc':\n",
    "                    current = acc\n",
    "                elif stopper=='epoch':\n",
    "                    current = epoch\n",
    "                if current >= running:\n",
    "                    running = current\n",
    "                    best_run = epoch+1\n",
    "                    best_model = copy.deepcopy(model.state_dict()) \n",
    "                \n",
    "            print(\"~ %s LOSS: %5.3f | ACC: %5.3f\" % (phase,loss,acc))\n",
    "            if current >= running and phase=='validate':\n",
    "                print(\"      BEST SO FAR ^ ^ ^\")\n",
    "        \n",
    "    return (best_run, best_model, train_losses, train_accs, val_losses, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Phylogenetic\" loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phylo_error(output, target):\n",
    "        \n",
    "    weights = np.ones((output.shape[0],output.shape[1]))\n",
    "\n",
    "    for i,t in enumerate(target):\n",
    "        t = t.cpu()\n",
    "        wIdc = np.where(t.detach().numpy()==1)[0]\n",
    "\n",
    "        if len(wIdc)==0:\n",
    "            weights[i] = 0.000001\n",
    "            continue\n",
    "        theseWeights = np.ones((len(fams)))\n",
    "        \n",
    "        for wIdx in wIdc:\n",
    "            thisWeight = famDistMatrix[wIdx].copy() # inter-fam\n",
    "            thisWeight[wIdx] =  1.00 - famDistMatrix[wIdx][wIdx].copy() # intra-fam\n",
    "            theseWeights+=thisWeight # add to existing list of fam distances, respectively (element wise)\n",
    "            \n",
    "        fWeight = theseWeights/len(fams) # take median / average\n",
    "        weights[i] = fWeight \n",
    "        \n",
    "    weights = torch.tensor(weights)\n",
    "    weights = weights.to(device)\n",
    "    crit = nn.BCELoss(reduction=my_reduction)\n",
    "    answer = crit(output, target) * weights.mean().float()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If training new model, set your parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "my_version = 'seq-coord'        \n",
    "my_loss = 'phylo'            \n",
    "\n",
    "my_stopper = 'loss'\n",
    "my_batch = 32\n",
    "my_epochs = 2\n",
    "my_lr = 0.0015\n",
    "\n",
    "my_reduction = 'sum'\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"No positive samples in y_true, true positive value should be meaningless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m all_best_runs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m all_models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mfolds\u001b[49m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m* * * * * * * * FOLD \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m * * * * * * * *\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     15\u001b[0m     fold_val_idc \u001b[38;5;241m=\u001b[39m fold\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "all_train_losses = []\n",
    "all_train_accs = []\n",
    "all_val_losses = []\n",
    "all_val_accs = []\n",
    "\n",
    "all_best_runs = []\n",
    "all_models = []\n",
    "\n",
    "for i,fold in enumerate(folds):\n",
    "    \n",
    "    print(\"\\n* * * * * * * * FOLD %d * * * * * * * *\\n\" %(i+1))\n",
    "    \n",
    "    fold_val_idc = fold\n",
    "    fold_train_idc = [x for x in range(len(train_motifs)) if x not in fold_val_idc]\n",
    "    \n",
    "    train_loader = get_loader(train_motifs,train_embedding,train_motifxFamMatrix,fold_train_idc,my_batch)\n",
    "    val_loader = get_loader(train_motifs,train_embedding,train_motifxFamMatrix,fold_val_idc,my_batch)\n",
    "    \n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = my_lr)\n",
    "    \n",
    "    (best_run, best_model, train_losses, train_accs, val_losses, val_accs) = \\\n",
    "                    train_model(train_loader, val_loader,\n",
    "                                model, optimizer,my_batch, \n",
    "                                my_epochs,my_stopper,my_version,\n",
    "                                my_loss)\n",
    "    \n",
    "    all_best_runs.append(best_run)\n",
    "    all_models.append(best_model)\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_train_accs.append(train_accs)\n",
    "    all_val_losses.append(val_losses)\n",
    "    all_val_accs.append(val_accs)\n",
    "    \n",
    "print(\"TIME: %5.3f mins\" % ((time.time()-s)/60))\n",
    "print(\"BEST RUNS:\",all_best_runs)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m run \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m??\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m# # # # # # # # # # # #\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m\"\u001b[39m\u001b[39mMODELS_multiclass/\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m run):\n\u001b[1;32m      6\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(\u001b[39m\"\u001b[39m\u001b[39mMODELS_multiclass/\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m run)\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i,model_weights \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(all_models):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# # # # # # # # # # # #\n",
    "run = '??'\n",
    "# # # # # # # # # # # #\n",
    "\n",
    "if not os.path.exists(\"MODELS_multiclass/%s/\" % run):\n",
    "    os.makedirs(\"MODELS_multiclass/%s/\" % run)\n",
    "for i,model_weights in enumerate(all_models):\n",
    "    torch.save(model_weights, \"MODELS_multiclass/%s/%d_weights\" % (run,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses and accuracies across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_train_losses_arr = np.zeros(my_epochs)\n",
    "all_train_accs_arr = np.zeros(my_epochs)\n",
    "all_val_losses_arr = np.zeros(my_epochs)\n",
    "all_val_accs_arr = np.zeros(my_epochs)\n",
    "\n",
    "for i in range(my_epochs):\n",
    "    all_train_losses_arr[i] = sum([all_train_losses[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    all_train_accs_arr[i] = sum([all_train_accs[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    all_val_losses_arr[i] = sum([all_val_losses[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    all_val_accs_arr[i] = sum([all_val_accs[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    \n",
    "if my_reduction=='sum':\n",
    "    all_train_losses_arr=all_train_losses_arr*.005\n",
    "    all_val_losses_arr=all_val_losses_arr*.005\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "\n",
    "plt.plot(all_train_losses_arr,label='Train loss',c='blue')\n",
    "plt.plot(all_val_losses_arr,label='Val loss',c='green')\n",
    "plt.plot(all_train_accs_arr,label='Train acc',c='red')\n",
    "plt.plot(all_val_accs_arr,label='Val acc',c='orange')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc='center right')\n",
    "plt.savefig(\"FIGS_multiclass/\" + run + \"_loss-acc\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b0f235dfb12f85291a5d0961e5e2f14d2c9dd145bc4f514acb05f4d86deb64c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
