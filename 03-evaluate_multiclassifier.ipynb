{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from multiclassifier import Model\n",
    "\n",
    "seedy = 666\n",
    "random.seed(seedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load motif data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_motifs = np.genfromtxt('data/train_motifs.csv',dtype='U')\n",
    "train_motifxFamMatrix = np.genfromtxt('data/train_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "test_motifs = np.genfromtxt('data/new_test_motifs.csv',dtype='U')\n",
    "test_motifxFamMatrix = np.genfromtxt('data/new_test_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "fams = np.genfromtxt('data/fams.csv',dtype='U')\n",
    "\n",
    "## Split data into folds in a stratified k-fold manner.\n",
    "\n",
    "def proba_mass_split(y, folds=5):\n",
    "    obs, classes = y.shape\n",
    "    dist = y.sum(axis=0).astype('float')\n",
    "    dist /= dist.sum()\n",
    "    index_list = []\n",
    "    fold_dist = np.zeros((folds, classes), dtype='float')\n",
    "    for _ in range(folds):\n",
    "        index_list.append([])\n",
    "    for i in range(obs):\n",
    "        if i < folds:\n",
    "            target_fold = i\n",
    "        else:\n",
    "            normed_folds = fold_dist.T / fold_dist.sum(axis=1)\n",
    "            how_off = normed_folds.T - dist\n",
    "            target_fold = np.argmin(np.dot((y[i] - .5).reshape(1, -1), how_off.T))\n",
    "        fold_dist[target_fold] += y[i]\n",
    "        index_list[target_fold].append(i)\n",
    "    return index_list\n",
    "\n",
    "np.random.seed(seedy)\n",
    "folds = proba_mass_split(train_motifxFamMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embedding coordinates and kinase family distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Get Siamese embedding coords.\n",
    "#############################################\n",
    "\n",
    "embedding = np.genfromtxt('MODELS_siam/embedding.csv',delimiter=',',dtype=float)\n",
    "train_embedding = embedding[ :len(train_motifs) ]\n",
    "test_embedding = embedding[ len(train_motifs): ]\n",
    "print(embedding.shape)\n",
    "\n",
    "#############################################\n",
    "# Get fam distance matrix for Phylo MSE loss.\n",
    "#############################################\n",
    "\n",
    "all_fams = (np.genfromtxt('data/fam_distances_blos62/fams.csv',dtype='U'))\n",
    "dist_matrix = (np.genfromtxt('data/fam_distances_blos62/dist_matrix.csv',delimiter=',',dtype=float))\n",
    "\n",
    "fam_idc = [np.where(all_fams==fam)[0][0] for fam in fams]\n",
    "fam_dist_matrix = dist_matrix[fam_idc][:,fam_idc]\n",
    "        \n",
    "# normalize fam distances\n",
    "fMax = np.max(fam_dist_matrix)\n",
    "fMin = np.min(fam_dist_matrix)\n",
    "\n",
    "fam_dist_matrix_scaled = np.array((fam_dist_matrix))\n",
    "for i in range(len(fams)):\n",
    "    for j in range(len(fams)):\n",
    "        fam_dist_matrix_scaled[i][j] = 1 - float(fam_dist_matrix[i][j]-fMin)/(fMax-fMin) \n",
    "fam_dist_matrix = fam_dist_matrix_scaled\n",
    "\n",
    "famDistMatrix = fam_dist_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc functions for data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINOS = 'XWGSAELQDMPFTRIHVNCY_K'\n",
    "\n",
    "def get_oneHot_motifs(motifs, AMINOS=AMINOS):\n",
    "    oneHot_motifs = []\n",
    "    for motif in motifs:\n",
    "        one_hotted = np.zeros((len(motif), len(AMINOS)),dtype=float)\n",
    "        for i,aa in enumerate(motif):\n",
    "            hot = AMINOS.find(aa)\n",
    "            one_hotted[i][hot] = 1\n",
    "        oneHot_motifs.append(one_hotted)\n",
    "    oneHot_motifs = np.asarray(oneHot_motifs)\n",
    "    oneHot_motifs = np.swapaxes(oneHot_motifs,1,2)\n",
    "    return oneHot_motifs\n",
    "\n",
    "def get_stacked_features(motifs, embeddings):\n",
    "    oneHot_motifs = get_oneHot_motifs(motifs)\n",
    "    squished_oneHots = oneHot_motifs.reshape(oneHot_motifs.shape[0],oneHot_motifs.shape[1]*\n",
    "                                         oneHot_motifs.shape[2])\n",
    "    stacked_features = np.hstack((squished_oneHots,embeddings))\n",
    "    stacked_features = torch.tensor(stacked_features)\n",
    "    return stacked_features        \n",
    "\n",
    "def get_loader(motifs,embedding,motifxFamMatrix,idc,my_batch):\n",
    "    these_motifs = motifs[idc]\n",
    "    this_embedding = embedding[idc]\n",
    "    X = get_stacked_features(these_motifs,this_embedding)\n",
    "    Y = torch.tensor(motifxFamMatrix[idc])\n",
    "    dataset = data_utils.TensorDataset(X, Y)\n",
    "    loader = data_utils.DataLoader(dataset, batch_size=my_batch, shuffle=True, drop_last=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, thresh=0.5):\n",
    "    \n",
    "    model.eval()\n",
    "    loader = get_loader(test_motifs,test_embedding,test_motifxFamMatrix,range(len(test_motifs)),len(test_motifs))\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        \n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        motif = inputs[:,:-embedding.shape[1]].reshape( len(test_motifs), len(AMINOS), len(train_motifs[0]) )\n",
    "        coords = inputs[:,-embedding.shape[1]:]\n",
    "        \n",
    "        outputs = model.forward(motif, coords)\n",
    "        \n",
    "        accuracy = 0\n",
    "        totTrues = 0\n",
    "        for i,out in enumerate(outputs):\n",
    "            pred = np.where(out.cpu().detach().numpy() > thresh)[0]\n",
    "            true = np.where(labels.data.cpu()[i]==1)[0]\n",
    "            totTrues += len(true)\n",
    "            accuracy += len(pred)\n",
    "\n",
    "        y_score = outputs.cpu().detach().numpy()\n",
    "        y_test = np.asarray(labels.cpu())\n",
    "                \n",
    "        return y_test, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = open(\"./run.cfg\", \"r\").read()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_y_scores = []\n",
    "all_y_test = []\n",
    "for i in range(5):\n",
    "    \n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(\"MODELS_multiclass/%s/%d_weights\" % (run,i)))\n",
    "    \n",
    "    y_test, y_score = eval_model(model)\n",
    "    all_y_scores.extend(y_score)\n",
    "    all_y_test.extend(y_test)\n",
    "    \n",
    "y_score = np.asarray(all_y_scores)\n",
    "y_test = np.asarray(all_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC\n",
    "\n",
    "\n",
    "\n",
    "FAM_IDC = [x for x in range(len(fams))]\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in FAM_IDC:\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in FAM_IDC]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in FAM_IDC:\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= len(FAM_IDC)\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRECISION-RECALL\n",
    "\n",
    "\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "for i in range(len(fams)):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())\n",
    "\n",
    "average_precision[\"micro\"] = average_precision_score(y_test, y_score, average=\"micro\")\n",
    "average_precision[\"macro\"] = average_precision_score(y_test, y_score, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_to_col = {'AKT': 'red',\n",
    "              'CDK': 'magenta',\n",
    "              'CK2': 'orange',\n",
    "              'MAPK': 'gold',\n",
    "              'PIKK': 'yellowgreen',\n",
    "              'PKA': 'turquoise',\n",
    "              'PKC': 'blue',\n",
    "              'SRC': 'purple'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from itertools import cycle\n",
    "\n",
    "plt.style.use('default')\n",
    "# fig, (ax1, ax2) = plt.subplots(2,figsize=(5,11))\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(11,5))\n",
    "\n",
    "lw = 1.25\n",
    "\n",
    "############################################################\n",
    "###################  AUROC #################################\n",
    "############################################################\n",
    "\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "l, = ax1.plot(0,0,color='white')\n",
    "lines.append(l)\n",
    "labels.append('micro-average (area = {0:0.3f})'.format(roc_auc[\"micro\"]))\n",
    "l, = ax1.plot(0,0,color='white')\n",
    "lines.append(l)\n",
    "labels.append('macro-average (area = {0:0.3f})'.format(roc_auc[\"macro\"]))\n",
    "\n",
    "for i,fam in enumerate(fams):\n",
    "    fclass = fams[i]\n",
    "    if fclass=='AKT':\n",
    "        fclass = 'Akt'\n",
    "    if fclass=='SRC':\n",
    "        fclass = 'Src'    \n",
    "    l, = ax1.plot(fpr[i], tpr[i], color=fam_to_col[fam], lw=lw,\n",
    "             label='{0} (area = {1:0.3f})'.format(fclass, roc_auc[i]))\n",
    "    labels.append('{0} (area = {1:0.3f})'.format(fclass, roc_auc[i]))\n",
    "    lines.append(l)\n",
    "\n",
    "fig.subplots_adjust(hspace=.275)\n",
    "ax1.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.tick_params(axis=\"x\", labelsize=10)\n",
    "ax1.tick_params(axis=\"y\", labelsize=10)\n",
    "ax1.set_xlabel('False Positive Rate',fontsize=12)\n",
    "ax1.set_ylabel('True Positive Rate',fontsize=12) \n",
    "ax1.set_title('ROC curve per kinase family',fontsize=12) \n",
    "labels, lines = zip(*sorted(zip(labels, lines), key=lambda t: t[0], reverse=False))\n",
    "ax1.legend(lines, labels, loc=(0.475, .0175), fontsize=7.5)  # (1.05, .0)\n",
    "\n",
    "############################################################\n",
    "###############  PRECISION-RECALL ##########################\n",
    "############################################################\n",
    "\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "l, = ax2.plot(0,0,color='white')\n",
    "lines.append(l)\n",
    "labels.append('micro-average (area = {0:0.3f})'.format(average_precision[\"micro\"]))\n",
    "l, = ax2.plot(0,0,color='white')\n",
    "lines.append(l)\n",
    "labels.append('macro-average (area = {0:0.3f})'.format(average_precision[\"macro\"]))\n",
    "\n",
    "for i,fam in enumerate(fams):\n",
    "    l, = ax2.plot(recall[i], precision[i], color=fam_to_col[fam], lw=lw)\n",
    "    lines.append(l)\n",
    "    fclass = fams[i]\n",
    "    if fclass=='AKT':\n",
    "        fclass = 'Akt'\n",
    "    if fclass=='SRC':\n",
    "        fclass = 'Src'\n",
    "    labels.append('{0} (area = {1:0.3f})'.format(fclass, average_precision[i]))\n",
    "\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "ax2.tick_params(axis=\"x\", labelsize=10)\n",
    "ax2.tick_params(axis=\"y\", labelsize=10)\n",
    "ax2.set_xlabel('Recall',fontsize=12) \n",
    "ax2.set_ylabel('Precision',fontsize=12) \n",
    "ax2.set_title('Precision-recall curve per kinase family',fontsize=12) \n",
    "\n",
    "labels, lines = zip(*sorted(zip(labels, lines), key=lambda t: t[0], reverse=False))\n",
    "ax2.legend(lines, labels, loc=(0.025, .0175), fontsize=7.5) # (1.05, .0)\n",
    "\n",
    "plt.savefig(\"FIGS_multiclass/%s_roc-prc\" % run, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.zeros((len(fams), len(fams)),dtype=float)\n",
    "\n",
    "for i,score in enumerate(y_score):\n",
    "    pred = np.where(score > 0.5000)[0]\n",
    "    if len(pred)<1:\n",
    "        pred = [np.argmax(score)]\n",
    "    true = np.where(y_test[i]==1)[0]\n",
    "    for p_idx in pred:\n",
    "        for t_idx in true:\n",
    "            confusion[p_idx][t_idx] += 1\n",
    "            \n",
    "labs = confusion.copy()\n",
    "\n",
    "for i in range(len(fams)):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "for i in range(len(fams)):\n",
    "    for j in range(len(fams)):\n",
    "        if math.isnan(confusion[i][j]) or confusion[i][j]==0:\n",
    "            confusion[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = sb.heatmap(confusion, annot=labs, cmap=\"GnBu_r\", fmt='1.0f',\n",
    "                      square=False, yticklabels=fams, xticklabels=fams )\n",
    "\n",
    "b, t = plt.ylim() \n",
    "plt.ylim(b, t) \n",
    "\n",
    "plt.xlabel(\"True label\",fontsize=12, labelpad=10)\n",
    "plt.ylabel(\"Predicted label\",fontsize=12, labelpad=10)\n",
    "plt.title(\"Confusion matrix for kinase labels\",fontsize=12, pad=12)\n",
    "plt.savefig(\"FIGS_multiclass/%s_confusion\" % run, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
