{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import distance\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "random.seed(666)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meow function to run after model is finished training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    return Audio('meow.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_motifs = np.genfromtxt('data/train_motifs.csv',dtype='U')\n",
    "train_motifxFamMatrix = np.genfromtxt('data/train_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "test_motifs = np.genfromtxt('data/new_test_motifs.csv',dtype='U')\n",
    "test_motifxFamMatrix = np.genfromtxt('data/new_test_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "fams = np.genfromtxt('data/fams.csv',dtype='U')\n",
    "\n",
    "all_motifs = np.hstack([train_motifs,test_motifs])\n",
    "all_motifxFamMatrix = np.vstack([train_motifxFamMatrix,test_motifxFamMatrix])\n",
    "\n",
    "X_train, X_val = train_test_split(range(len(train_motifs)), test_size=0.1, random_state=666)\n",
    "\n",
    "print(len(X_train), len(X_val), len(test_motifs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_length = 3\n",
    "\n",
    "def get_gram_seq(motif,gram_length=1):\n",
    "    gram_seq = []\n",
    "    for i in range(len(motif)):\n",
    "        gram = motif[i:i+gram_length]\n",
    "        gram_seq.append(gram)\n",
    "    return gram_seq\n",
    "\n",
    "def get_encoded_motifs(grammed_motifs, all_grams):\n",
    "    gram_counts = Counter(all_grams)\n",
    "    gram_list = sorted(gram_counts, key=gram_counts.get, reverse=True)\n",
    "    gram_to_int = {gram:idx+1 for idx, gram in enumerate(gram_list)}  \n",
    "    encoded_motifs = [[gram_to_int[gram] for gram in motif] for motif in grammed_motifs]\n",
    "    return encoded_motifs, gram_to_int, gram_list\n",
    "\n",
    "AMINOS = 'XWGSAELQDMPFTRIHVNCY_K'\n",
    "\n",
    "all_grams = []\n",
    "train_grammed_motifs = []\n",
    "for motif in train_motifs:\n",
    "    grammed_motif = get_gram_seq(motif,gram_length)\n",
    "    train_grammed_motifs.append(grammed_motif)\n",
    "    all_grams.extend(grammed_motif)\n",
    "    \n",
    "test_grammed_motifs = []\n",
    "for motif in test_motifs:\n",
    "    grammed_motif = get_gram_seq(motif,gram_length)\n",
    "    test_grammed_motifs.append(grammed_motif)\n",
    "    all_grams.extend(grammed_motif)\n",
    "    \n",
    "vocab_size = len(set(all_grams))\n",
    "print(\"vocab size:\",vocab_size)\n",
    "\n",
    "train_encoded_motifs, gram_to_int, gram_list = get_encoded_motifs(train_grammed_motifs, all_grams)\n",
    "test_encoded_motifs, gram_to_int, gram_list = get_encoded_motifs(test_grammed_motifs, all_grams)\n",
    "all_encoded_motifs = train_encoded_motifs + test_encoded_motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions relevant to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_jaccard(set1, set2):\n",
    "    assert isinstance(set1, set), \"`set1` is not a set.\"\n",
    "    assert isinstance(set2, set), \"`set2` is not a set.\"\n",
    "    return 1 - (len(set1.intersection(set2)) / len(set1.union(set2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_motif_and_fam(idc):\n",
    "    mIdx = random.choice(idc)  \n",
    "    motif = train_encoded_motifs[mIdx] \n",
    "    fIdx = np.where(train_motifxFamMatrix[mIdx]==1)\n",
    "    theseFams = fams[fIdx]\n",
    "    return (mIdx,motif,fIdx,theseFams)\n",
    "\n",
    "def get_batch(idc,batch_size):\n",
    "    batch = []\n",
    "    switch = 0\n",
    "    \n",
    "    while switch < batch_size:\n",
    "        mIdx_1, motif_1, fIdx_1, fams_1 = get_random_motif_and_fam(idc)\n",
    "        mIdx_2, motif_2, fIdx_2, fams_2 = get_random_motif_and_fam(idc)\n",
    "        \n",
    "        if len(fams_1)==0 and len(fams_2)==0: \n",
    "            continue\n",
    "        \n",
    "        label = my_jaccard(set(fams_1), set(fams_2))\n",
    "        if switch%2 != round(label):     # math.ceil(label):\n",
    "            continue\n",
    "        switch += 1\n",
    "            \n",
    "        triplet = [motif_1, motif_2, label]\n",
    "        batch.append(triplet)\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "def evaluate(model, idc, criterion, iters, batch_size, margin, dist_type):\n",
    "    model.eval()\n",
    "    loss_history = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i in range(iters):\n",
    "            batch = get_batch(idc, batch_size)\n",
    "            motifs_net1 = torch.stack([torch.tensor(x[0]).to(device) for x in batch])\n",
    "            motifs_net2 = torch.stack([torch.tensor(x[1]).to(device) for x in batch])\n",
    "            labels = torch.stack([torch.tensor(x[2]).to(device) for x in batch])\n",
    "            \n",
    "            embeds_1, embeds_2 = model(motifs_net1, motifs_net2)\n",
    "            loss = criterion(embeds_1, embeds_2, labels,margin, dist_type)\n",
    "                \n",
    "            loss_history += loss.item()\n",
    "            \n",
    "    return loss_history / iters\n",
    "\n",
    "    \n",
    "def train(model, idc, optimizer, criterion, iters, batch_size, margin, dist_type):\n",
    "    model.train()\n",
    "    loss_history = 0\n",
    "    \n",
    "    for i in range(iters):\n",
    "            \n",
    "        batch = get_batch(idc, batch_size)\n",
    "        motifs_net1 = torch.stack([torch.tensor(x[0]).to(device) for x in batch])\n",
    "        motifs_net2 = torch.stack([torch.tensor(x[1]).to(device) for x in batch])\n",
    "        labels = torch.stack([torch.tensor(x[2]).to(device) for x in batch])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        embeds_1, embeds_2 = model(motifs_net1, motifs_net2)\n",
    "        loss = criterion(embeds_1, embeds_2, labels, margin, dist_type)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        loss_history += loss.item()\n",
    "        \n",
    "    return loss_history / iters\n",
    "\n",
    "class SiameseLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, z1, z2, label, margin=2.0, dist_type='L2'):\n",
    "        ''' Calculates the pairwise loss given two embeddings and their 0/1 label.\n",
    "            margin: somewhere between 0.0 and 3.0\n",
    "            dist_type: manhattan (L1) or euclidean (L2)\n",
    "        '''\n",
    "        if dist_type=='L2':\n",
    "            distance = F.pairwise_distance(z1, z2)\n",
    "        elif dist_type=='L1':\n",
    "            distance = torch.sum( torch.abs(z1-z2), axis=1)\n",
    "        siam_loss = torch.mean((1-label) * torch.pow(distance, 2) +\n",
    "                                (label) * torch.pow(torch.clamp(margin - distance, min=0.0), 2))\n",
    "        return siam_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "            \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=64)   \n",
    "        \n",
    "        self.lstm = nn.LSTM(64, 128, bidirectional=True,num_layers=2,\n",
    "                            batch_first=True,dropout=0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*2*15, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, 100)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.drpt = nn.Dropout(p=0.0)\n",
    "                \n",
    "    def forward_once(self, motif): \n",
    "        \n",
    "        embedded = self.embedding(motif)\n",
    "        lstmed, _ = self.lstm(embedded)\n",
    "        flattened = lstmed.reshape(lstmed.shape[0], lstmed.shape[1]*lstmed.shape[2])        \n",
    "    \n",
    "        fc1 = self.fc1(flattened)\n",
    "        fc1 = self.relu(fc1)\n",
    "        fc1 = self.drpt(fc1)\n",
    "        \n",
    "        fc2 = self.fc2(fc1)\n",
    "        fc2 = self.relu(fc2)\n",
    "        fc2 = self.drpt(fc2)\n",
    "        \n",
    "        fc3 = self.fc3(fc2)\n",
    "        fc3 = self.relu(fc3)\n",
    "\n",
    "        out = self.out(fc3)\n",
    "\n",
    "        return out\n",
    "        \n",
    "    def forward(self, motifs_net1, motifs_net2):\n",
    "        embed_1 = self.forward_once(motifs_net1)\n",
    "        embed_2 = self.forward_once(motifs_net2)\n",
    "        return (embed_1, embed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model() \n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.005 ) \n",
    "criterion = SiameseLoss()\n",
    "\n",
    "bs = 64\n",
    "\n",
    "# A sub_iter is a single run through the network\n",
    "sub_iters = 100\n",
    "# Loss is calculated per super_iter (collection of sub_iters)\n",
    "super_iters = 10\n",
    "\n",
    "my_margin = 1.5\n",
    "my_dist_type = 'L1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Device:\",device,\"\\n\")\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "best_val_loss = float('inf')\n",
    "total_time = time.time()\n",
    "\n",
    "best_super = 0\n",
    "for i in range(super_iters):\n",
    "    start = time.time()\n",
    "    train_loss = train(model, X_train, optimizer, criterion, \n",
    "                       iters=sub_iters, batch_size=bs, \n",
    "                       margin=my_margin, dist_type=my_dist_type)\n",
    "    val_loss = evaluate(model, X_val, criterion, \n",
    "                        iters=sub_iters, batch_size=bs,\n",
    "                        margin=my_margin, dist_type=my_dist_type)\n",
    "    \n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    \n",
    "    if val_loss <= best_val_loss:\n",
    "\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_super = i\n",
    "\n",
    "    print(\"Time: %5.3f secs, Super iter %d\\n* Train loss %5.4f | Val loss: %5.4f\" % \n",
    "          ( time.time()-start, i+1, train_loss, val_loss ))\n",
    "\n",
    "final_model = Model().to(device)\n",
    "final_model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(\"--------------------\\nLast super iter of learning:\",best_super)\n",
    "print(\"Total train time: %5.3f mins\" % ( (time.time()-total_time)/60 ))\n",
    "allDone()\n",
    "\n",
    "# # # # # # # # # # # #\n",
    "run = datetime.datetime.now().isoformat()\n",
    "with open(\"run.cfg\", \"w\") as f:\n",
    "    f.write(run)\n",
    "torch.save(model.state_dict(), \"MODELS_siam/siameseWeights_%s\" % run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, enc_mots):\n",
    "    model.eval()\n",
    "    to_embed = torch.tensor(np.array((enc_mots))).to(device)\n",
    "    embedding = model.forward_once(to_embed)\n",
    "    return embedding.cpu().detach().numpy()\n",
    "\n",
    "embedded = get_embedding(model,all_encoded_motifs)   #range(len(motifs)))\n",
    "df = pd.DataFrame(embedded,dtype=float)\n",
    "df.to_csv(\"MODELS_siam/emb_%s_embedding.csv\" % (run),header=None,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "umapper = umap.UMAP(\n",
    "    n_neighbors=20, # changed from 200\n",
    "    min_dist=0.5, # changed from 0.1\n",
    "    n_components=2,\n",
    "    metric='euclidean' )\n",
    "\n",
    "s = time.time()\n",
    "pos_umap = umapper.fit_transform(embedded)\n",
    "# allDone()\n",
    "\n",
    "print (\"secs: %5.3f\" % (time.time()-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "f = 'FIGS_siam/' + run + \"/\" \n",
    "if not os.path.exists(f):\n",
    "    os.mkdir(f)\n",
    "\n",
    "label_size = 45\n",
    "title_size = 50\n",
    "tick_size = 40\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "colors = ['red','#CD0000','deepskyblue','blue','green','blueviolet','orange','magenta','blueviolet','violet','deeppink','crimson','mediumslateblue','brown']\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.scatter(pos_umap[:, 0], pos_umap[:, 1], marker = 'o',s=5,color='black', alpha=1) #alpha=0.25)\n",
    "plt.title(\"Siamese latent space, UMAP reduction\",fontsize=title_size,y=1.01)\n",
    "plt.xlabel(\"UMAP-1\",fontsize=label_size)\n",
    "plt.ylabel(\"UMAP-2\",fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.savefig( f + \"noHighlights\")\n",
    "plt.show()\n",
    "\n",
    "pop_fams = ['PKC', 'AKT', 'CDK', 'MAPK', 'SRC', 'CK2', 'PKA', 'PIKK']\n",
    "# pop_fams = ['CAMK-UNIQUE', 'DYRK', 'CAMKL', 'STE20', 'PKC', 'AKT', 'CDK', 'MAPK', 'SRC', 'CK2', 'PKA', 'PIKK']\n",
    "\n",
    "\n",
    "i = -1\n",
    "for _,fam in enumerate(pop_fams):\n",
    "    \n",
    "    i+=1\n",
    "    fIdx = np.where(fams==fam)[0][0]\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title((\"Siamese latent space, UMAP reduction: %s\" % fam),fontsize=title_size,y=1.01)\n",
    "    plt.xticks(fontsize=tick_size)                            \n",
    "    plt.yticks(fontsize=tick_size)\n",
    "    plt.xlabel(\"UMAP-1\",fontsize=label_size)\n",
    "    plt.ylabel(\"UMAP-2\",fontsize=label_size)\n",
    "    plt.scatter(pos_umap[:, 0], pos_umap[:, 1], marker = 'o',s=25,color='grey',alpha=0.30)\n",
    "    for mIdx, (x, y) in enumerate(zip(pos_umap[:, 0], pos_umap[:, 1])):\n",
    "        if all_motifs[mIdx] not in test_motifs:\n",
    "            continue\n",
    "        elif all_motifxFamMatrix[mIdx][fIdx]==1:\n",
    "            plt.scatter(x,y,marker='o',s=200,c=colors[i],alpha=1.0,edgecolors='black')          \n",
    "    plt.savefig((f+\"%s\" % fam))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b0f235dfb12f85291a5d0961e5e2f14d2c9dd145bc4f514acb05f4d86deb64c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
