{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import Audio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from multiclassifier import Model\n",
    "\n",
    "seedy = 666\n",
    "random.seed(seedy)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meow function to run after model is finished training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    return Audio('meow.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load motif data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_motifs = np.genfromtxt('data_dev/train_motifs.csv',dtype='U')\n",
    "train_motifxFamMatrix = np.genfromtxt('data_dev/train_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "test_motifs = np.genfromtxt('data_dev/new_test_motifs.csv',dtype='U')\n",
    "test_motifxFamMatrix = np.genfromtxt('data_dev/new_test_motifxFamMatrix.csv',delimiter=',',dtype=int)\n",
    "fams = np.genfromtxt('data_dev/fams.csv',dtype='U')\n",
    "\n",
    "## Split data into folds in a stratified k-fold manner.\n",
    "\n",
    "def proba_mass_split(y, folds=5):\n",
    "    obs, classes = y.shape\n",
    "    dist = y.sum(axis=0).astype('float')\n",
    "    dist /= dist.sum()\n",
    "    index_list = []\n",
    "    fold_dist = np.zeros((folds, classes), dtype='float')\n",
    "    for _ in range(folds):\n",
    "        index_list.append([])\n",
    "    for i in range(obs):\n",
    "        if i < folds:\n",
    "            target_fold = i\n",
    "        else:\n",
    "            normed_folds = fold_dist.T / fold_dist.sum(axis=1)\n",
    "            how_off = normed_folds.T - dist\n",
    "            target_fold = np.argmin(np.dot((y[i] - .5).reshape(1, -1), how_off.T))\n",
    "        fold_dist[target_fold] += y[i]\n",
    "        index_list[target_fold].append(i)\n",
    "    return index_list\n",
    "\n",
    "np.random.seed(seedy)\n",
    "folds = proba_mass_split(train_motifxFamMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embedding coordinates and kinase family distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Get Siamese embedding coords.\n",
    "#############################################\n",
    "\n",
    "embedding = np.genfromtxt('MODELS_siam/embedding.csv',delimiter=',',dtype=float)\n",
    "train_embedding = embedding[ :len(train_motifs) ]\n",
    "test_embedding = embedding[ len(train_motifs): ]\n",
    "print(embedding.shape)\n",
    "\n",
    "#############################################\n",
    "# Get fam distance matrix for Phylo MSE loss.\n",
    "#############################################\n",
    "\n",
    "all_fams = (np.genfromtxt('data_dev/fam_distances_blos62/fams.csv',dtype='U'))\n",
    "dist_matrix = (np.genfromtxt('data_dev/fam_distances_blos62/dist_matrix.csv',delimiter=',',dtype=float))\n",
    "\n",
    "fam_idc = [np.where(all_fams==fam)[0][0] for fam in fams]\n",
    "fam_dist_matrix = dist_matrix[fam_idc][:,fam_idc]\n",
    "        \n",
    "# normalize fam distances\n",
    "fMax = np.max(fam_dist_matrix)\n",
    "fMin = np.min(fam_dist_matrix)\n",
    "\n",
    "fam_dist_matrix_scaled = np.array((fam_dist_matrix))\n",
    "for i in range(len(fams)):\n",
    "    for j in range(len(fams)):\n",
    "        fam_dist_matrix_scaled[i][j] = 1 - float(fam_dist_matrix[i][j]-fMin)/(fMax-fMin) \n",
    "fam_dist_matrix = fam_dist_matrix_scaled\n",
    "\n",
    "famDistMatrix = fam_dist_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc functions for data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINOS = 'XWGSAELQDMPFTRIHVNCY_K'\n",
    "\n",
    "def get_oneHot_motifs(motifs, AMINOS=AMINOS):\n",
    "    oneHot_motifs = []\n",
    "    for motif in motifs:\n",
    "        one_hotted = np.zeros((len(motif), len(AMINOS)),dtype=float)\n",
    "        for i,aa in enumerate(motif):\n",
    "            hot = AMINOS.find(aa)\n",
    "            one_hotted[i][hot] = 1\n",
    "        oneHot_motifs.append(one_hotted)\n",
    "    oneHot_motifs = np.asarray(oneHot_motifs)\n",
    "    oneHot_motifs = np.swapaxes(oneHot_motifs,1,2)\n",
    "    return oneHot_motifs\n",
    "\n",
    "def get_stacked_features(motifs, embeddings):\n",
    "    oneHot_motifs = get_oneHot_motifs(motifs)\n",
    "    squished_oneHots = oneHot_motifs.reshape(oneHot_motifs.shape[0],oneHot_motifs.shape[1]*\n",
    "                                         oneHot_motifs.shape[2])\n",
    "    stacked_features = np.hstack((squished_oneHots,embeddings))\n",
    "    stacked_features = torch.tensor(stacked_features)\n",
    "    return stacked_features        \n",
    "\n",
    "\n",
    "def get_loader(motifs,embedding,motifxFamMatrix,idc,my_batch):\n",
    "    these_motifs = motifs[idc]\n",
    "    this_embedding = embedding[idc]\n",
    "    X = get_stacked_features(these_motifs,this_embedding)\n",
    "    Y = torch.tensor(motifxFamMatrix[idc])\n",
    "    dataset = data_utils.TensorDataset(X, Y)\n",
    "    loader = data_utils.DataLoader(dataset, batch_size=my_batch, shuffle=True, drop_last=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_microROC(y_test, y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(len(fams)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    return auc(fpr_micro, tpr_micro)\n",
    "\n",
    "def train_model(train_loader, val_loader, model, optimizer, batch_size, num_epochs, stopper='loss', \n",
    "                version='seq-coord', this_loss='phylo'):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    running = - math.inf\n",
    "    current = running\n",
    "    best_run = 0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(\"Epoch\",epoch+1)\n",
    "        for phase in ['train','validate']:\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            if phase=='train':\n",
    "                loader = train_loader\n",
    "                model.train()\n",
    "            else:\n",
    "                loader = val_loader\n",
    "                model.eval()\n",
    "                \n",
    "            for inputs,labels in loader:\n",
    "                inputs = inputs.float().to(device)\n",
    "                labels = labels.float().to(device)\n",
    "                motif = inputs[:,:-embedding.shape[1]].reshape( batch_size, len(AMINOS), len(train_motifs[0]) )\n",
    "                coords = inputs[:,-embedding.shape[1]:]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model.forward(motif, coords, version)\n",
    "                    if this_loss=='phylo' and version=='seq-coord':\n",
    "                        loss = phylo_error(outputs,labels)\n",
    "                    elif this_loss!='phylo':\n",
    "                        criterion = nn.BCELoss() # BCE loss is the usual loss to use.\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                y_test = np.asarray(labels.cpu())\n",
    "                y_score = outputs.cpu().detach().numpy()\n",
    "                acc = get_microROC(y_test, y_score)\n",
    "                running_acc += acc\n",
    "            \n",
    "            loss = running_loss / len(loader) \n",
    "            acc =  running_acc / len(loader) \n",
    "            \n",
    "            if phase=='train':\n",
    "                train_losses.append(loss)\n",
    "                train_accs.append(acc)\n",
    "                \n",
    "            elif phase=='validate':\n",
    "                val_losses.append(loss)\n",
    "                val_accs.append(acc)\n",
    "                \n",
    "                if stopper=='loss':\n",
    "                    current = -loss\n",
    "                elif stopper=='acc':\n",
    "                    current = acc\n",
    "                elif stopper=='epoch':\n",
    "                    current = epoch\n",
    "                if current >= running:\n",
    "                    running = current\n",
    "                    best_run = epoch+1\n",
    "                    best_model = copy.deepcopy(model.state_dict()) \n",
    "                \n",
    "            print(\"~ %s LOSS: %5.3f | ACC: %5.3f\" % (phase,loss,acc))\n",
    "            if current >= running and phase=='validate':\n",
    "                print(\"      BEST SO FAR ^ ^ ^\")\n",
    "        \n",
    "    return (best_run, best_model, train_losses, train_accs, val_losses, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Phylogenetic\" loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phylo_error(output, target):\n",
    "        \n",
    "    weights = np.ones((output.shape[0],output.shape[1]))\n",
    "\n",
    "    for i,t in enumerate(target):\n",
    "        t = t.cpu()\n",
    "        wIdc = np.where(t.detach().numpy()==1)[0]\n",
    "\n",
    "        if len(wIdc)==0:\n",
    "            weights[i] = 0.000001\n",
    "            continue\n",
    "        theseWeights = np.ones((len(fams)))\n",
    "        \n",
    "        for wIdx in wIdc:\n",
    "            thisWeight = famDistMatrix[wIdx].copy() # inter-fam\n",
    "            thisWeight[wIdx] =  1.00 - famDistMatrix[wIdx][wIdx].copy() # intra-fam\n",
    "            theseWeights+=thisWeight # add to existing list of fam distances, respectively (element wise)\n",
    "            \n",
    "        fWeight = theseWeights/len(fams) # take median / average\n",
    "        weights[i] = fWeight \n",
    "        \n",
    "    weights = torch.tensor(weights)\n",
    "    weights = weights.to(device)\n",
    "    crit = nn.BCELoss(reduction=my_reduction)\n",
    "    answer = crit(output, target) * weights.mean().float()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If training new model, set your parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "my_version = 'seq-coord'        \n",
    "my_loss = 'phylo'            \n",
    "\n",
    "my_stopper = 'loss'\n",
    "my_batch = 32\n",
    "my_epochs = 1\n",
    "my_lr = 0.0015\n",
    "\n",
    "my_reduction = 'sum'\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "\n",
    "all_train_losses = []\n",
    "all_train_accs = []\n",
    "all_val_losses = []\n",
    "all_val_accs = []\n",
    "\n",
    "all_best_runs = []\n",
    "all_models = []\n",
    "\n",
    "for i,fold in enumerate(folds):\n",
    "    \n",
    "    print(\"\\n* * * * * * * * FOLD %d * * * * * * * *\\n\" %(i+1))\n",
    "    \n",
    "    fold_val_idc = fold\n",
    "    fold_train_idc = [x for x in range(len(train_motifs)) if x not in fold_val_idc]\n",
    "    \n",
    "    train_loader = get_loader(train_motifs,train_embedding,train_motifxFamMatrix,fold_train_idc,my_batch)\n",
    "    val_loader = get_loader(train_motifs,train_embedding,train_motifxFamMatrix,fold_val_idc,my_batch)\n",
    "    \n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = my_lr)\n",
    "    \n",
    "    (best_run, best_model, train_losses, train_accs, val_losses, val_accs) = \\\n",
    "                    train_model(train_loader, val_loader,\n",
    "                                model, optimizer,my_batch, \n",
    "                                my_epochs,my_stopper,my_version,\n",
    "                                my_loss)\n",
    "    \n",
    "    all_best_runs.append(best_run)\n",
    "    all_models.append(best_model)\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_train_accs.append(train_accs)\n",
    "    all_val_losses.append(val_losses)\n",
    "    all_val_accs.append(val_accs)\n",
    "    \n",
    "print(\"TIME: %5.3f mins\" % ((time.time()-s)/60))\n",
    "print(\"BEST RUNS:\",all_best_runs)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # #\n",
    "run = '??'\n",
    "# # # # # # # # # # # #\n",
    "\n",
    "if not os.path.exists(\"MODELS_multiclass/%s/\" % run):\n",
    "    os.makedirs(\"MODELS_multiclass/%s/\" % run)\n",
    "for i,model_weights in enumerate(all_models):\n",
    "    torch.save(model_weights, \"MODELS_multiclass/%s/%d_weights\" % (run,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses and accuracies across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_losses_arr = np.zeros(my_epochs)\n",
    "all_train_accs_arr = np.zeros(my_epochs)\n",
    "all_val_losses_arr = np.zeros(my_epochs)\n",
    "all_val_accs_arr = np.zeros(my_epochs)\n",
    "\n",
    "for i in range(my_epochs):\n",
    "    all_train_losses_arr[i] = sum([all_train_losses[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    all_train_accs_arr[i] = sum([all_train_accs[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    all_val_losses_arr[i] = sum([all_val_losses[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    all_val_accs_arr[i] = sum([all_val_accs[j][i] for j in range(len(folds))]) / len(folds)\n",
    "    \n",
    "if my_reduction=='sum':\n",
    "    all_train_losses_arr=all_train_losses_arr*.005\n",
    "    all_val_losses_arr=all_val_losses_arr*.005\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "\n",
    "plt.plot(all_train_losses_arr,label='Train loss',c='blue')\n",
    "plt.plot(all_val_losses_arr,label='Val loss',c='green')\n",
    "plt.plot(all_train_accs_arr,label='Train acc',c='red')\n",
    "plt.plot(all_val_accs_arr,label='Val acc',c='orange')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc='center right')\n",
    "plt.savefig(\"FIGS_multiclass/\" + run + \"_loss-acc\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
